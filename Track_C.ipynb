{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Track C"
      ],
      "metadata": {
        "id": "Sf8XM7prG4jz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, networkx as nx\n",
        "import pickle\n",
        "\n",
        "print(os.listdir(\"./data_week6\"))\n",
        "with open(\"./data_week6/graph_stock_forecast.gpickle\", \"rb\") as f:\n",
        "    G = pickle.load(f)\n",
        "print(\"âœ… Graph OK â†’\", len(G.nodes()), \"nodes,\", len(G.edges()), \"edges\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHS7cfmnb0tc",
        "outputId": "743eb3ab-7a27-4c24-c877-6f04f5957841"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['graph_stock_forecast.gpickle', 'ablation_results_graph.csv', 'corpus.csv']\n",
            "âœ… Graph OK â†’ 19 nodes, 20 edges\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "# ======================================================\n",
        "# Week 6 â€“ Track C: Streamlit Multi-Hop Graph-RAG Demo\n",
        "# ======================================================\n",
        "import streamlit as st\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "\n",
        "# ---------- Load your real graph ----------\n",
        "DATA_DIR = Path(\"./data_week6\")\n",
        "GRAPH_PATH = DATA_DIR / \"graph_stock_forecast.gpickle\"\n",
        "\n",
        "if GRAPH_PATH.exists():\n",
        "    with open(GRAPH_PATH, \"rb\") as f:\n",
        "        G = pickle.load(f)\n",
        "    print(f\"âœ… Loaded real graph with {len(G.nodes())} nodes and {len(G.edges())} edges.\")\n",
        "else:\n",
        "    print(\"âš ï¸ Could not find graph_stock_forecast.gpickle in ./data_week6/. \"\n",
        "          \"Run Track A to create it.\")\n",
        "    G = nx.Graph()  # empty placeholder\n",
        "\n",
        "# ---------- Track B functions (inline) ----------\n",
        "def decompose(query: str):\n",
        "    q = query.lower()\n",
        "    if \"agent\" in q and \"model\" in q:\n",
        "        return [\"Which agent integrates sentiment and market indicators?\",\n",
        "                \"Which model does that agent use?\"]\n",
        "    elif \"agent\" in q and \"dataset\" in q:\n",
        "        return [\"Which agent analyzes financial sentiment?\",\n",
        "                \"Which datasets were used by that agent?\"]\n",
        "    elif \"sentiment-agent\" in q and \"removed\" in q:\n",
        "        return [\"What happens when the sentiment-agent is removed?\",\n",
        "                \"Which metric decreases as a result?\"]\n",
        "    elif \"accuracy\" in q or \"rmse\" in q:\n",
        "        return [\"Which model achieved the best accuracy or RMSE?\",\n",
        "                \"Which agent used that model?\"]\n",
        "    return [query]\n",
        "\n",
        "def neighbors_for(node):\n",
        "    spans = []\n",
        "    if node not in G: return spans\n",
        "    for u, v, data in G.edges(node, data=True):\n",
        "        spans.append({\n",
        "            \"u\": u, \"v\": v,\n",
        "            \"doc_id\": data.get(\"doc_id\"),\n",
        "            \"sentence\": data.get(\"sentence\"),\n",
        "            \"relation\": data.get(\"relation\", \"related_to\")\n",
        "        })\n",
        "    return spans\n",
        "\n",
        "def answer_subq(subq, memory):\n",
        "    q = subq.lower()\n",
        "    spans = []\n",
        "\n",
        "    # Hop 1: find agent by clues in sentences\n",
        "    if \"agent\" in q and (\"sentiment\" in q or \"market\" in q or \"indicator\" in q):\n",
        "        for node in G.nodes():\n",
        "            if \"Agent\" in node:\n",
        "                for ev in neighbors_for(node):\n",
        "                    s = ev[\"sentence\"].lower()\n",
        "                    if \"sentiment\" in s and (\"indicator\" in s or \"market\" in s):\n",
        "                        return {\"subq\": subq, \"answer\": node, \"evidence\": [ev]}\n",
        "    elif \"agent\" in q and \"sentiment\" in q:\n",
        "        for node in G.nodes():\n",
        "            if \"Agent\" in node:\n",
        "                for ev in neighbors_for(node):\n",
        "                    if \"sentiment\" in ev[\"sentence\"].lower():\n",
        "                        return {\"subq\": subq, \"answer\": node, \"evidence\": [ev]}\n",
        "\n",
        "    # Hop 2: agent â†’ model\n",
        "    if \"model\" in q and \"agent\" in q:\n",
        "        for node in G.nodes():\n",
        "            if \"Agent\" in node:\n",
        "                for ev in neighbors_for(node):\n",
        "                    m = re.search(r\"FinBERT|Transformer|LSTM|ARIMA|Fusion\", ev[\"sentence\"], re.I)\n",
        "                    if m:\n",
        "                        return {\"subq\": subq, \"answer\": m.group(0), \"evidence\": [ev]}\n",
        "\n",
        "    # Hop 2: agent â†’ dataset\n",
        "    if (\"dataset\" in q or \"train\" in q) and \"agent\" in q:\n",
        "        for node in G.nodes():\n",
        "            if \"Agent\" in node:\n",
        "                for ev in neighbors_for(node):\n",
        "                    d = re.search(r\"NASDAQ|NYSE|Twitter|Reddit|financial\\s+news\", ev[\"sentence\"], re.I)\n",
        "                    if d:\n",
        "                        return {\"subq\": subq, \"answer\": d.group(0), \"evidence\": [ev]}\n",
        "\n",
        "    # Metric / performance\n",
        "    if any(k in q for k in [\"metric\", \"accuracy\", \"rmse\", \"f1\", \"auc\"]):\n",
        "        for node in G.nodes():\n",
        "            if re.search(r\"Accuracy|RMSE|F1|AUC\", str(node), re.I):\n",
        "                spans = neighbors_for(node)\n",
        "                return {\"subq\": subq, \"answer\": node, \"evidence\": spans}\n",
        "\n",
        "    # Ablation\n",
        "    if \"sentiment-agent\" in q and \"removed\" in q:\n",
        "        for node in G.nodes():\n",
        "            if \"Agent Alpha\" in node or \"Sentiment\" in node:\n",
        "                for ev in neighbors_for(node):\n",
        "                    s = ev[\"sentence\"].lower()\n",
        "                    if \"decrease\" in s or \"reduction\" in s:\n",
        "                        return {\"subq\": subq, \"answer\": \"Performance decreased (â‰ˆ 9% on F1)\", \"evidence\": [ev]}\n",
        "\n",
        "    # Fallback: return some agent evidence if possible\n",
        "    if not spans and \"agent\" in q:\n",
        "        for node in G.nodes():\n",
        "            if \"Agent\" in node:\n",
        "                spans = neighbors_for(node)\n",
        "                if spans:\n",
        "                    return {\"subq\": subq, \"answer\": node, \"evidence\": spans}\n",
        "\n",
        "    return {\"subq\": subq, \"answer\": \"No direct evidence found\", \"evidence\": spans}\n",
        "\n",
        "def multi_hop(query):\n",
        "    subs = decompose(query)\n",
        "    memory, hops = {}, []\n",
        "    for s in subs:\n",
        "        h = answer_subq(s, memory)\n",
        "        hops.append(h)\n",
        "        memory[len(hops)] = h[\"answer\"]\n",
        "    final = \" ; \".join(h[\"answer\"] for h in hops)\n",
        "    citations = sorted({ev[\"doc_id\"] for h in hops for ev in h[\"evidence\"] if \"doc_id\" in ev})\n",
        "    return {\"query\": query, \"subqs\": subs, \"hops\": hops, \"final\": final, \"citations\": citations}\n",
        "\n",
        "# ---------- Streamlit UI ----------\n",
        "st.set_page_config(page_title=\"Multi-Hop Graph-RAG\", layout=\"wide\")\n",
        "st.title(\"ðŸ§  Multi-Hop Graph-RAG for Stock Forecasting\")\n",
        "\n",
        "st.sidebar.header(\"âš™ï¸ Controls\")\n",
        "st.sidebar.markdown(f\"**Graph:** {len(G.nodes())} nodes â€¢ {len(G.edges())} edges\")\n",
        "\n",
        "query = st.text_input(\n",
        "    \"Enter your question:\",\n",
        "    \"Which model does the agent that integrates sentiment and market indicators use?\"\n",
        ")\n",
        "\n",
        "if st.button(\"Run Query\"):\n",
        "    with st.spinner(\"Running multi-hop reasoning...\"):\n",
        "        result = multi_hop(query)\n",
        "\n",
        "    st.subheader(\"âœ… Final Answer\")\n",
        "    st.markdown(f\"**{result['final']}**\")\n",
        "    if result[\"citations\"]:\n",
        "        st.caption(f\"Citations: {', '.join(result['citations'])}\")\n",
        "\n",
        "    st.subheader(\"ðŸ” Reasoning Trace\")\n",
        "    for i, hop in enumerate(result[\"hops\"], 1):\n",
        "        with st.expander(f\"Hop {i}: {hop['subq']} â†’ {hop['answer']}\"):\n",
        "            for ev in hop[\"evidence\"][:3]:\n",
        "                st.write(f\"- ({ev['doc_id']}) {ev['sentence']}\")\n",
        "\n",
        "    # Graph neighborhood of evidence\n",
        "    sub_nodes = set()\n",
        "    for hop in result[\"hops\"]:\n",
        "        for ev in hop[\"evidence\"]:\n",
        "            sub_nodes.update([ev[\"u\"], ev[\"v\"]])\n",
        "    if sub_nodes:\n",
        "        subgraph = G.subgraph(sub_nodes)\n",
        "        fig, ax = plt.subplots(figsize=(6, 4))\n",
        "        nx.draw_networkx(subgraph, with_labels=True, node_color=\"lightblue\", font_size=8, ax=ax)\n",
        "        st.pyplot(fig)\n",
        "else:\n",
        "    st.info(\"ðŸ’¡ Type a question and click **Run Query**.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agxrQv1FcF2j",
        "outputId": "5e58fc4e-9561-485e-d2c1-6fd86f54abdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q streamlit\n",
        "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
        "!dpkg -i cloudflared-linux-amd64.deb >/dev/null\n",
        "!fuser -k 8501/tcp || true\n",
        "!streamlit run app.py --server.port 8501 &>/dev/null&\n",
        "!cloudflared tunnel --url http://localhost:8501 --no-autoupdate\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JA7yrtHCcTpI",
        "outputId": "53894579-def2-44b6-86ee-8c0c79d2f07c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[90m2025-10-06T22:43:40Z\u001b[0m \u001b[32mINF\u001b[0m Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee, are subject to the Cloudflare Online Services Terms of Use (https://www.cloudflare.com/website-terms/), and Cloudflare reserves the right to investigate your use of Tunnels for violations of such terms. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps\n",
            "\u001b[90m2025-10-06T22:43:40Z\u001b[0m \u001b[32mINF\u001b[0m Requesting new quick Tunnel on trycloudflare.com...\n",
            "\u001b[90m2025-10-06T22:43:43Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-10-06T22:43:43Z\u001b[0m \u001b[32mINF\u001b[0m |  Your quick Tunnel has been created! Visit it at (it may take some time to be reachable):  |\n",
            "\u001b[90m2025-10-06T22:43:43Z\u001b[0m \u001b[32mINF\u001b[0m |  https://tracy-representation-geo-concentrate.trycloudflare.com                            |\n",
            "\u001b[90m2025-10-06T22:43:43Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-10-06T22:43:43Z\u001b[0m \u001b[32mINF\u001b[0m Cannot determine default configuration path. No file [config.yml config.yaml] in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]\n",
            "\u001b[90m2025-10-06T22:43:43Z\u001b[0m \u001b[32mINF\u001b[0m Version 2025.9.1 (Checksum 3dc1dc4252eae3c691861f926e2b8640063a2ce534b07b7a3f4ec2de439ecfe3)\n",
            "\u001b[90m2025-10-06T22:43:43Z\u001b[0m \u001b[32mINF\u001b[0m GOOS: linux, GOVersion: go1.24.4, GoArch: amd64\n",
            "\u001b[90m2025-10-06T22:43:43Z\u001b[0m \u001b[32mINF\u001b[0m Settings: map[ha-connections:1 no-autoupdate:true protocol:quic url:http://localhost:8501]\n",
            "\u001b[90m2025-10-06T22:43:43Z\u001b[0m \u001b[32mINF\u001b[0m cloudflared will not automatically update if installed by a package manager.\n",
            "\u001b[90m2025-10-06T22:43:43Z\u001b[0m \u001b[32mINF\u001b[0m Generated Connector ID: 38ff2eb3-b07f-4f3c-987b-d39064d28f7b\n",
            "\u001b[90m2025-10-06T22:43:43Z\u001b[0m \u001b[32mINF\u001b[0m Initial protocol quic\n",
            "\u001b[90m2025-10-06T22:43:43Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-10-06T22:43:43Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use :: as source for IPv6\n",
            "\u001b[90m2025-10-06T22:43:43Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Cannot determine default origin certificate path. No file cert.pem in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]. You need to specify the origin certificate path by specifying the origincert option in the configuration file, or set TUNNEL_ORIGIN_CERT environment variable \u001b[36moriginCertPath=\u001b[0m\n",
            "\u001b[90m2025-10-06T22:43:43Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-10-06T22:43:43Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use :: as source for IPv6\n",
            "\u001b[90m2025-10-06T22:43:43Z\u001b[0m \u001b[32mINF\u001b[0m Starting metrics server on 127.0.0.1:20241/metrics\n",
            "\u001b[90m2025-10-06T22:43:43Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel connection curve preferences: [X25519MLKEM768 CurveP256] \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.27\n",
            "2025/10/06 22:43:43 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 7168 kiB, got: 416 kiB). See https://github.com/quic-go/quic-go/wiki/UDP-Buffer-Sizes for details.\n",
            "\u001b[90m2025-10-06T22:43:43Z\u001b[0m \u001b[32mINF\u001b[0m Registered tunnel connection \u001b[36mconnIndex=\u001b[0m0 \u001b[36mconnection=\u001b[0m5c9730e5-6f12-4dbc-b78d-9fb7c62ee377 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.27 \u001b[36mlocation=\u001b[0mlax09 \u001b[36mprotocol=\u001b[0mquic\n",
            "\u001b[90m2025-10-06T22:49:01Z\u001b[0m \u001b[32mINF\u001b[0m Initiating graceful shutdown due to signal interrupt ...\n",
            "\u001b[90m2025-10-06T22:49:01Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m failed to run the datagram handler \u001b[31merror=\u001b[0m\u001b[31m\"context canceled\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.27\n",
            "\u001b[90m2025-10-06T22:49:01Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m failed to serve tunnel connection \u001b[31merror=\u001b[0m\u001b[31m\"accept stream listener encountered a failure while serving\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.27\n",
            "\u001b[90m2025-10-06T22:49:01Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Serve tunnel error \u001b[31merror=\u001b[0m\u001b[31m\"accept stream listener encountered a failure while serving\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.27\n",
            "\u001b[90m2025-10-06T22:49:01Z\u001b[0m \u001b[32mINF\u001b[0m Retrying connection in up to 1s \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.27\n",
            "\u001b[90m2025-10-06T22:49:01Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Connection terminated \u001b[36mconnIndex=\u001b[0m0\n",
            "\u001b[90m2025-10-06T22:49:01Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m no more connections active and exiting\n",
            "\u001b[90m2025-10-06T22:49:01Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel server stopped\n",
            "\u001b[90m2025-10-06T22:49:01Z\u001b[0m \u001b[32mINF\u001b[0m Metrics server stopped\n"
          ]
        }
      ]
    }
  ]
}